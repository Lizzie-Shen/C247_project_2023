{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YMlsVYVVj7b"
      },
      "source": [
        "## (i) Importing the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T21:23:41.325324Z",
          "iopub.status.busy": "2023-03-17T21:23:41.322394Z",
          "iopub.status.idle": "2023-03-17T21:24:05.930333Z",
          "shell.execute_reply": "2023-03-17T21:24:05.928807Z",
          "shell.execute_reply.started": "2023-03-17T21:23:41.325281Z"
        },
        "id": "pSeXLkOEVj7b",
        "outputId": "d3c0fa0f-8599-4ace-9f78-b7916bb48c33",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-nlp\n",
            "  Downloading keras_nlp-0.4.1-py3-none-any.whl (466 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.8/466.8 KB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from keras-nlp) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from keras-nlp) (1.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras-nlp) (23.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-text->keras-nlp) (0.13.0)\n",
            "Requirement already satisfied: tensorflow<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-text->keras-nlp) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (3.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (2.11.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (15.0.6.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (23.3.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (1.51.3)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (2.11.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (3.19.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (63.4.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (0.31.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (0.40.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (6.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->keras-nlp) (3.2.2)\n",
            "Installing collected packages: tensorflow-text, keras-nlp\n",
            "Successfully installed keras-nlp-0.4.1 tensorflow-text-2.11.0\n"
          ]
        }
      ],
      "source": [
        "%pip install keras-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T21:24:33.574571Z",
          "iopub.status.busy": "2023-03-17T21:24:33.574123Z",
          "iopub.status.idle": "2023-03-17T21:24:40.980612Z",
          "shell.execute_reply": "2023-03-17T21:24:40.979524Z",
          "shell.execute_reply.started": "2023-03-17T21:24:33.574522Z"
        },
        "id": "1YSv6jOZVj7c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Reference 1: Vaswani, Ashish, et al. “Attention Is All You Need.” ArXiv.org, 6 Dec. 2017, https://arxiv.org/abs/1706.03762. \n",
        "#Reference 2: Keras Team. “Keras Documentation: Transformerencoder Layer.” Keras, https://keras.io/api/keras_nlp/layers/transformer_encoder/. \n",
        "#Reference 3: Monsoor, Tonmoy, et al. \"CNN with data preprocessing.ipynb.\" BruinLearn, https://bruinlearn.ucla.edu/courses/154235/files/12794459/download?download_frd=1\n",
        "\n",
        "#The following code is adopted from the \"CNN with data preprocessing.ipynb.\" by Tonmoy Monsoor from ECE C247.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten,Dropout,Reshape\n",
        "from keras.layers import Conv2D,BatchNormalization,MaxPooling2D,Reshape, LeakyReLU\n",
        "from keras.utils import to_categorical\n",
        "from keras_nlp.layers import TransformerEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "np.random.seed(12345)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_naxrHOeVj7c"
      },
      "source": [
        "## (ii)(a) Loading and visualizing the dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T21:24:40.983094Z",
          "iopub.status.busy": "2023-03-17T21:24:40.982421Z",
          "iopub.status.idle": "2023-03-17T21:24:44.862412Z",
          "shell.execute_reply": "2023-03-17T21:24:44.861473Z",
          "shell.execute_reply.started": "2023-03-17T21:24:40.983060Z"
        },
        "id": "LJOX9qqCVj7d",
        "outputId": "3af6c791-2988-42b7-f08d-2e9a6db9df92",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f389d138eb0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Loading and visualizing the data\n",
        "\n",
        "## Loading the dataset\n",
        "\n",
        "\n",
        "X_test = np.load(\"/content/drive/MyDrive/Project Data/X_test.npy\")\n",
        "y_test = np.load(\"/content/drive/MyDrive/Project Data/y_test.npy\")\n",
        "person_train_valid = np.load(\"/content/drive/MyDrive/Project Data/person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"/content/drive/MyDrive/Project Data/X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"/content/drive/MyDrive/Project Data/y_train_valid.npy\")\n",
        "person_test = np.load(\"/content/drive/MyDrive/Project Data/person_test.npy\")\n",
        "\n",
        "## Adjusting the labels so that \n",
        "\n",
        "# Cue onset left - 0\n",
        "# Cue onset right - 1\n",
        "# Cue onset foot - 2\n",
        "# Cue onset tongue - 3\n",
        "\n",
        "y_train_valid -= 769\n",
        "y_test -= 769\n",
        "\n",
        "## Visualizing the data\n",
        "\n",
        "ch_data = X_train_valid[:,8,:] # extracts the 9th channel from the data\n",
        "\n",
        "\n",
        "class_0_ind = np.where(y_train_valid == 0) # finds the indices where the label is 0\n",
        "ch_data_class_0 = ch_data[class_0_ind] # finds the data where label is 0\n",
        "avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0) # finds the average representation of the 9th channel when label is 0\n",
        "\n",
        "\n",
        "class_1_ind = np.where(y_train_valid == 1)\n",
        "ch_data_class_1 = ch_data[class_1_ind]\n",
        "avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n",
        "\n",
        "class_2_ind = np.where(y_train_valid == 2)\n",
        "ch_data_class_2 = ch_data[class_2_ind]\n",
        "avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n",
        "\n",
        "class_3_ind = np.where(y_train_valid == 3)\n",
        "ch_data_class_3 = ch_data[class_3_ind]\n",
        "avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n",
        "\n",
        "\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_0)\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_1)\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_2)\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_3)\n",
        "plt.axvline(x=500, label='line at t=500',c='cyan')\n",
        "\n",
        "plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aUqXUdJ9Vj7e"
      },
      "source": [
        "## (ii)(b) Preprocessing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC5k9yLRVj7f"
      },
      "source": [
        "![EEG_prep.png](attachment:EEG_prep.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T21:24:58.858696Z",
          "iopub.status.busy": "2023-03-17T21:24:58.858317Z",
          "iopub.status.idle": "2023-03-17T21:24:58.868578Z",
          "shell.execute_reply": "2023-03-17T21:24:58.867366Z",
          "shell.execute_reply.started": "2023-03-17T21:24:58.858661Z"
        },
        "id": "zCDmcCDLVj7f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Preparing the trimmed dataset based on the specified time bins. \n",
        "\n",
        "def data_prep(X,y,sub_sample,average,noise,time):\n",
        "    \n",
        "    total_X = None\n",
        "    total_y = None\n",
        "    \n",
        "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
        "    X = X[:,:,0:time]\n",
        "    #print('Shape of X after trimming:',X.shape)\n",
        "    \n",
        "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
        "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
        "    \n",
        "    \n",
        "    total_X = X_max\n",
        "    total_y = y\n",
        "    #print('Shape of X after maxpooling:',total_X.shape)\n",
        "    \n",
        "    # Averaging + noise \n",
        "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
        "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
        "    \n",
        "    total_X = np.vstack((total_X, X_average))\n",
        "    total_y = np.hstack((total_y, y))\n",
        "    #print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
        "    \n",
        "    # Subsampling\n",
        "    \n",
        "    for i in range(sub_sample):\n",
        "        \n",
        "        X_subsample = X[:, :, i::sub_sample] + \\\n",
        "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
        "            \n",
        "        total_X = np.vstack((total_X, X_subsample))\n",
        "        total_y = np.hstack((total_y, y))\n",
        "        \n",
        "    \n",
        "    #print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
        "    return total_X,total_y\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t8Z2jBAqVj7g"
      },
      "source": [
        "## (iii) Defining the architecture of CNN+Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T21:26:43.743002Z",
          "iopub.status.busy": "2023-03-17T21:26:43.742052Z",
          "iopub.status.idle": "2023-03-17T21:26:43.755620Z",
          "shell.execute_reply": "2023-03-17T21:26:43.754448Z",
          "shell.execute_reply.started": "2023-03-17T21:26:43.742946Z"
        },
        "id": "LtD86hU3Vj7h",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def CNN_Transformer(intermediate_dim=6, num_heads=2, add_layer = False,time=250):\n",
        "    # Building the CNN model using sequential class\n",
        "    basic_cnn_model = Sequential()\n",
        "    # Conv. block 1\n",
        "    basic_cnn_model.add(TransformerEncoder(intermediate_dim=intermediate_dim,num_heads=num_heads,dropout=0.5,activation=\"elu\"))\n",
        "    basic_cnn_model.add(Reshape((time,1,22)))\n",
        "\n",
        "    basic_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.5))\n",
        "\n",
        "    # Conv. block 2\n",
        "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.5))\n",
        "\n",
        "    # Conv. block 3\n",
        "    basic_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.5))\n",
        "\n",
        "    # Conv. block 4\n",
        "\n",
        "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "    # Output layer with Softmax activation\n",
        "    basic_cnn_model.add(Flatten()) # Flattens the input\n",
        "    basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
        "\n",
        "    basic_cnn_model.build((None,time,22))\n",
        "\n",
        "    # Printing the model summary\n",
        "    #basic_cnn_model.summary()\n",
        "    return basic_cnn_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (iv) Compiling the CNN+Transformer model and Training the model based on different specified time bins (250, 500, 750, 1000). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T21:32:27.806033Z",
          "iopub.status.busy": "2023-03-17T21:32:27.805626Z",
          "iopub.status.idle": "2023-03-17T21:32:27.825207Z",
          "shell.execute_reply": "2023-03-17T21:32:27.823593Z",
          "shell.execute_reply.started": "2023-03-17T21:32:27.805995Z"
        },
        "id": "qyxmTGr9Vj7k",
        "outputId": "b22b5608-192a-40ba-a0c8-743f7f156fc8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(443,)\n",
            "(8460, 125, 22)\n",
            "Epoch 1/100\n",
            "133/133 [==============================] - 8s 12ms/step - loss: 1.9009 - accuracy: 0.3007\n",
            "Epoch 2/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 1.5202 - accuracy: 0.3456\n",
            "Epoch 3/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 1.3483 - accuracy: 0.4021\n",
            "Epoch 4/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 1.2400 - accuracy: 0.4454\n",
            "Epoch 5/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 1.1857 - accuracy: 0.4759\n",
            "Epoch 6/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 1.1476 - accuracy: 0.5041\n",
            "Epoch 7/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 1.1145 - accuracy: 0.5234\n",
            "Epoch 8/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 1.0777 - accuracy: 0.5372\n",
            "Epoch 9/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 1.0460 - accuracy: 0.5543\n",
            "Epoch 10/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 1.0212 - accuracy: 0.5735\n",
            "Epoch 11/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.9927 - accuracy: 0.5833\n",
            "Epoch 12/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.9514 - accuracy: 0.6072\n",
            "Epoch 13/100\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 0.9193 - accuracy: 0.6201\n",
            "Epoch 14/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.8973 - accuracy: 0.6378\n",
            "Epoch 15/100\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 0.8557 - accuracy: 0.6506\n",
            "Epoch 16/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.8217 - accuracy: 0.6701\n",
            "Epoch 17/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.7838 - accuracy: 0.6787\n",
            "Epoch 18/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.7649 - accuracy: 0.6969\n",
            "Epoch 19/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.7418 - accuracy: 0.7040\n",
            "Epoch 20/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.7108 - accuracy: 0.7110\n",
            "Epoch 21/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.6787 - accuracy: 0.7389\n",
            "Epoch 22/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.6600 - accuracy: 0.7413\n",
            "Epoch 23/100\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 0.6260 - accuracy: 0.7600\n",
            "Epoch 24/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.6162 - accuracy: 0.7612\n",
            "Epoch 25/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.5989 - accuracy: 0.7665\n",
            "Epoch 26/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.5810 - accuracy: 0.7734\n",
            "Epoch 27/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.5453 - accuracy: 0.7915\n",
            "Epoch 28/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.5421 - accuracy: 0.7894\n",
            "Epoch 29/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.5111 - accuracy: 0.8054\n",
            "Epoch 30/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.4862 - accuracy: 0.8059\n",
            "Epoch 31/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.4855 - accuracy: 0.8158\n",
            "Epoch 32/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.4709 - accuracy: 0.8186\n",
            "Epoch 33/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.4580 - accuracy: 0.8252\n",
            "Epoch 34/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.4433 - accuracy: 0.8285\n",
            "Epoch 35/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.4343 - accuracy: 0.8306\n",
            "Epoch 36/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.4399 - accuracy: 0.8281\n",
            "Epoch 37/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.4181 - accuracy: 0.8396\n",
            "Epoch 38/100\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 0.4136 - accuracy: 0.8457\n",
            "Epoch 39/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.4051 - accuracy: 0.8436\n",
            "Epoch 40/100\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 0.3940 - accuracy: 0.8456\n",
            "Epoch 41/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.3934 - accuracy: 0.8512\n",
            "Epoch 42/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.3940 - accuracy: 0.8468\n",
            "Epoch 43/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.3786 - accuracy: 0.8565\n",
            "Epoch 44/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.3634 - accuracy: 0.8617\n",
            "Epoch 45/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.3593 - accuracy: 0.8623\n",
            "Epoch 46/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.3645 - accuracy: 0.8602\n",
            "Epoch 47/100\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 0.3396 - accuracy: 0.8704\n",
            "Epoch 48/100\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 0.3568 - accuracy: 0.8637\n",
            "Epoch 49/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.3332 - accuracy: 0.8766\n",
            "Epoch 50/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.3235 - accuracy: 0.8762\n",
            "Epoch 51/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.3320 - accuracy: 0.8739\n",
            "Epoch 52/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.3187 - accuracy: 0.8830\n",
            "Epoch 53/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.3179 - accuracy: 0.8780\n",
            "Epoch 54/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.3032 - accuracy: 0.8861\n",
            "Epoch 55/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.3054 - accuracy: 0.8849\n",
            "Epoch 56/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.3105 - accuracy: 0.8829\n",
            "Epoch 57/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2919 - accuracy: 0.8891\n",
            "Epoch 58/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.3003 - accuracy: 0.8882\n",
            "Epoch 59/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2856 - accuracy: 0.8933\n",
            "Epoch 60/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2901 - accuracy: 0.8924\n",
            "Epoch 61/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.2949 - accuracy: 0.8885\n",
            "Epoch 62/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2948 - accuracy: 0.8902\n",
            "Epoch 63/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.2764 - accuracy: 0.8981\n",
            "Epoch 64/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.2720 - accuracy: 0.9000\n",
            "Epoch 65/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.2793 - accuracy: 0.8949\n",
            "Epoch 66/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2654 - accuracy: 0.8989\n",
            "Epoch 67/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.2682 - accuracy: 0.9021\n",
            "Epoch 68/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2748 - accuracy: 0.8967\n",
            "Epoch 69/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2688 - accuracy: 0.8963\n",
            "Epoch 70/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2671 - accuracy: 0.9002\n",
            "Epoch 71/100\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 0.2791 - accuracy: 0.8950\n",
            "Epoch 72/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2535 - accuracy: 0.9043\n",
            "Epoch 73/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2508 - accuracy: 0.9053\n",
            "Epoch 74/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2487 - accuracy: 0.9063\n",
            "Epoch 75/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2394 - accuracy: 0.9102\n",
            "Epoch 76/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2588 - accuracy: 0.9063\n",
            "Epoch 77/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2454 - accuracy: 0.9071\n",
            "Epoch 78/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2409 - accuracy: 0.9128\n",
            "Epoch 79/100\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 0.2291 - accuracy: 0.9129\n",
            "Epoch 80/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2401 - accuracy: 0.9095\n",
            "Epoch 81/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2499 - accuracy: 0.9084\n",
            "Epoch 82/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2433 - accuracy: 0.9113\n",
            "Epoch 83/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2411 - accuracy: 0.9113\n",
            "Epoch 84/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2338 - accuracy: 0.9103\n",
            "Epoch 85/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2386 - accuracy: 0.9135\n",
            "Epoch 86/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2253 - accuracy: 0.9161\n",
            "Epoch 87/100\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 0.2232 - accuracy: 0.9182\n",
            "Epoch 88/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2283 - accuracy: 0.9151\n",
            "Epoch 89/100\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 0.2342 - accuracy: 0.9128\n",
            "Epoch 90/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2328 - accuracy: 0.9132\n",
            "Epoch 91/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2155 - accuracy: 0.9201\n",
            "Epoch 92/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2209 - accuracy: 0.9173\n",
            "Epoch 93/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2288 - accuracy: 0.9142\n",
            "Epoch 94/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2091 - accuracy: 0.9217\n",
            "Epoch 95/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2297 - accuracy: 0.9148\n",
            "Epoch 96/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2120 - accuracy: 0.9233\n",
            "Epoch 97/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.2047 - accuracy: 0.9241\n",
            "Epoch 98/100\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 0.2042 - accuracy: 0.9227\n",
            "Epoch 99/100\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 0.2202 - accuracy: 0.9191\n",
            "Epoch 100/100\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 0.2135 - accuracy: 0.9197\n",
            "0.7212189435958862\n",
            "(443,)\n",
            "(8460, 250, 22)\n",
            "Epoch 1/100\n",
            "133/133 [==============================] - 9s 18ms/step - loss: 1.9184 - accuracy: 0.3056\n",
            "Epoch 2/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 1.4919 - accuracy: 0.3781\n",
            "Epoch 3/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 1.3015 - accuracy: 0.4294\n",
            "Epoch 4/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 1.2107 - accuracy: 0.4695\n",
            "Epoch 5/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 1.1558 - accuracy: 0.5030\n",
            "Epoch 6/100\n",
            "133/133 [==============================] - 3s 19ms/step - loss: 1.1123 - accuracy: 0.5281\n",
            "Epoch 7/100\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 1.0772 - accuracy: 0.5435\n",
            "Epoch 8/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 1.0266 - accuracy: 0.5723\n",
            "Epoch 9/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.9838 - accuracy: 0.6012\n",
            "Epoch 10/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.9295 - accuracy: 0.6233\n",
            "Epoch 11/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.8795 - accuracy: 0.6434\n",
            "Epoch 12/100\n",
            "133/133 [==============================] - 3s 19ms/step - loss: 0.8318 - accuracy: 0.6665\n",
            "Epoch 13/100\n",
            "133/133 [==============================] - 2s 19ms/step - loss: 0.7939 - accuracy: 0.6885\n",
            "Epoch 14/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.7631 - accuracy: 0.6976\n",
            "Epoch 15/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.7216 - accuracy: 0.7184\n",
            "Epoch 16/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.6882 - accuracy: 0.7292\n",
            "Epoch 17/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.6593 - accuracy: 0.7402\n",
            "Epoch 18/100\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 0.6468 - accuracy: 0.7491\n",
            "Epoch 19/100\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 0.6019 - accuracy: 0.7625\n",
            "Epoch 20/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.5784 - accuracy: 0.7742\n",
            "Epoch 21/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.5733 - accuracy: 0.7772\n",
            "Epoch 22/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.5257 - accuracy: 0.7982\n",
            "Epoch 23/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.5119 - accuracy: 0.8053\n",
            "Epoch 24/100\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 0.5059 - accuracy: 0.8025\n",
            "Epoch 25/100\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 0.4747 - accuracy: 0.8150\n",
            "Epoch 26/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.4522 - accuracy: 0.8239\n",
            "Epoch 27/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.4581 - accuracy: 0.8240\n",
            "Epoch 28/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.4246 - accuracy: 0.8364\n",
            "Epoch 29/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.4158 - accuracy: 0.8389\n",
            "Epoch 30/100\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 0.3883 - accuracy: 0.8508\n",
            "Epoch 31/100\n",
            "133/133 [==============================] - 3s 21ms/step - loss: 0.3834 - accuracy: 0.8539\n",
            "Epoch 32/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.3603 - accuracy: 0.8618\n",
            "Epoch 33/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.3537 - accuracy: 0.8671\n",
            "Epoch 34/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.3507 - accuracy: 0.8651\n",
            "Epoch 35/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.3379 - accuracy: 0.8727\n",
            "Epoch 36/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.3365 - accuracy: 0.8728\n",
            "Epoch 37/100\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 0.3252 - accuracy: 0.8765\n",
            "Epoch 38/100\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 0.3174 - accuracy: 0.8755\n",
            "Epoch 39/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.3142 - accuracy: 0.8829\n",
            "Epoch 40/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2971 - accuracy: 0.8900\n",
            "Epoch 41/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.3008 - accuracy: 0.8852\n",
            "Epoch 42/100\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 0.2848 - accuracy: 0.8935\n",
            "Epoch 43/100\n",
            "133/133 [==============================] - 3s 21ms/step - loss: 0.2804 - accuracy: 0.8937\n",
            "Epoch 44/100\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 0.2820 - accuracy: 0.8936\n",
            "Epoch 45/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2815 - accuracy: 0.8943\n",
            "Epoch 46/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2804 - accuracy: 0.8929\n",
            "Epoch 47/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2510 - accuracy: 0.9091\n",
            "Epoch 48/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2582 - accuracy: 0.9043\n",
            "Epoch 49/100\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 0.2528 - accuracy: 0.9033\n",
            "Epoch 50/100\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 0.2472 - accuracy: 0.9121\n",
            "Epoch 51/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2303 - accuracy: 0.9155\n",
            "Epoch 52/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.2536 - accuracy: 0.9072\n",
            "Epoch 53/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2389 - accuracy: 0.9079\n",
            "Epoch 54/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2374 - accuracy: 0.9100\n",
            "Epoch 55/100\n",
            "133/133 [==============================] - 3s 21ms/step - loss: 0.2237 - accuracy: 0.9182\n",
            "Epoch 56/100\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 0.2452 - accuracy: 0.9099\n",
            "Epoch 57/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2295 - accuracy: 0.9130\n",
            "Epoch 58/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.2058 - accuracy: 0.9210\n",
            "Epoch 59/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2120 - accuracy: 0.9220\n",
            "Epoch 60/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2191 - accuracy: 0.9202\n",
            "Epoch 61/100\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 0.2089 - accuracy: 0.9204\n",
            "Epoch 62/100\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 0.2102 - accuracy: 0.9187\n",
            "Epoch 63/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.2040 - accuracy: 0.9229\n",
            "Epoch 64/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.2133 - accuracy: 0.9202\n",
            "Epoch 65/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.2081 - accuracy: 0.9217\n",
            "Epoch 66/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.2087 - accuracy: 0.9222\n",
            "Epoch 67/100\n",
            "133/133 [==============================] - 3s 19ms/step - loss: 0.1919 - accuracy: 0.9278\n",
            "Epoch 68/100\n",
            "133/133 [==============================] - 2s 19ms/step - loss: 0.1946 - accuracy: 0.9258\n",
            "Epoch 69/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.2014 - accuracy: 0.9258\n",
            "Epoch 70/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.2082 - accuracy: 0.9240\n",
            "Epoch 71/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1979 - accuracy: 0.9272\n",
            "Epoch 72/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1949 - accuracy: 0.9284\n",
            "Epoch 73/100\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 0.1804 - accuracy: 0.9313\n",
            "Epoch 74/100\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 0.1824 - accuracy: 0.9310\n",
            "Epoch 75/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.1842 - accuracy: 0.9319\n",
            "Epoch 76/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1815 - accuracy: 0.9356\n",
            "Epoch 77/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.1811 - accuracy: 0.9313\n",
            "Epoch 78/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1682 - accuracy: 0.9378\n",
            "Epoch 79/100\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 0.1818 - accuracy: 0.9338\n",
            "Epoch 80/100\n",
            "133/133 [==============================] - 3s 21ms/step - loss: 0.1908 - accuracy: 0.9305\n",
            "Epoch 81/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1668 - accuracy: 0.9388\n",
            "Epoch 82/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1825 - accuracy: 0.9363\n",
            "Epoch 83/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.1724 - accuracy: 0.9371\n",
            "Epoch 84/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1671 - accuracy: 0.9381\n",
            "Epoch 85/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1667 - accuracy: 0.9384\n",
            "Epoch 86/100\n",
            "133/133 [==============================] - 3s 21ms/step - loss: 0.1727 - accuracy: 0.9366\n",
            "Epoch 87/100\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 0.1675 - accuracy: 0.9401\n",
            "Epoch 88/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1711 - accuracy: 0.9370\n",
            "Epoch 89/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1688 - accuracy: 0.9381\n",
            "Epoch 90/100\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 0.1622 - accuracy: 0.9413\n",
            "Epoch 91/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1649 - accuracy: 0.9421\n",
            "Epoch 92/100\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 0.1599 - accuracy: 0.9405\n",
            "Epoch 93/100\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 0.1637 - accuracy: 0.9387\n",
            "Epoch 94/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1723 - accuracy: 0.9364\n",
            "Epoch 95/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1627 - accuracy: 0.9407\n",
            "Epoch 96/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1730 - accuracy: 0.9342\n",
            "Epoch 97/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1561 - accuracy: 0.9459\n",
            "Epoch 98/100\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 0.1553 - accuracy: 0.9420\n",
            "Epoch 99/100\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 0.1621 - accuracy: 0.9377\n",
            "Epoch 100/100\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 0.1601 - accuracy: 0.9407\n",
            "0.7240406274795532\n",
            "(443,)\n",
            "(8460, 375, 22)\n",
            "Epoch 1/100\n",
            "133/133 [==============================] - 10s 24ms/step - loss: 1.9489 - accuracy: 0.2876\n",
            "Epoch 2/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 1.5339 - accuracy: 0.3429\n",
            "Epoch 3/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 1.3498 - accuracy: 0.3918\n",
            "Epoch 4/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 1.2420 - accuracy: 0.4499\n",
            "Epoch 5/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 1.1487 - accuracy: 0.4991\n",
            "Epoch 6/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 1.1050 - accuracy: 0.5311\n",
            "Epoch 7/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 1.0478 - accuracy: 0.5576\n",
            "Epoch 8/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 1.0224 - accuracy: 0.5723\n",
            "Epoch 9/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.9688 - accuracy: 0.6046\n",
            "Epoch 10/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.9320 - accuracy: 0.6164\n",
            "Epoch 11/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.8878 - accuracy: 0.6371\n",
            "Epoch 12/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.8543 - accuracy: 0.6589\n",
            "Epoch 13/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.8233 - accuracy: 0.6762\n",
            "Epoch 14/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.7730 - accuracy: 0.6910\n",
            "Epoch 15/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.7461 - accuracy: 0.7118\n",
            "Epoch 16/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.7049 - accuracy: 0.7190\n",
            "Epoch 17/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.6719 - accuracy: 0.7312\n",
            "Epoch 18/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.6477 - accuracy: 0.7461\n",
            "Epoch 19/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.6271 - accuracy: 0.7547\n",
            "Epoch 20/100\n",
            "133/133 [==============================] - 4s 26ms/step - loss: 0.6013 - accuracy: 0.7591\n",
            "Epoch 21/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.5797 - accuracy: 0.7717\n",
            "Epoch 22/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.5475 - accuracy: 0.7863\n",
            "Epoch 23/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.5359 - accuracy: 0.7930\n",
            "Epoch 24/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.5210 - accuracy: 0.8021\n",
            "Epoch 25/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.4861 - accuracy: 0.8130\n",
            "Epoch 26/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.4731 - accuracy: 0.8213\n",
            "Epoch 27/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.4574 - accuracy: 0.8241\n",
            "Epoch 28/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.4283 - accuracy: 0.8356\n",
            "Epoch 29/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.4202 - accuracy: 0.8420\n",
            "Epoch 30/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.3925 - accuracy: 0.8483\n",
            "Epoch 31/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.3859 - accuracy: 0.8528\n",
            "Epoch 32/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.3733 - accuracy: 0.8592\n",
            "Epoch 33/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.3795 - accuracy: 0.8545\n",
            "Epoch 34/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.3620 - accuracy: 0.8603\n",
            "Epoch 35/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.3463 - accuracy: 0.8704\n",
            "Epoch 36/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.3503 - accuracy: 0.8689\n",
            "Epoch 37/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.3295 - accuracy: 0.8704\n",
            "Epoch 38/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.3226 - accuracy: 0.8765\n",
            "Epoch 39/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.3099 - accuracy: 0.8850\n",
            "Epoch 40/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.3142 - accuracy: 0.8838\n",
            "Epoch 41/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.3042 - accuracy: 0.8887\n",
            "Epoch 42/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2790 - accuracy: 0.8955\n",
            "Epoch 43/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2888 - accuracy: 0.8924\n",
            "Epoch 44/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2871 - accuracy: 0.8894\n",
            "Epoch 45/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.2643 - accuracy: 0.9013\n",
            "Epoch 46/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2687 - accuracy: 0.8988\n",
            "Epoch 47/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.2612 - accuracy: 0.9013\n",
            "Epoch 48/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2597 - accuracy: 0.9024\n",
            "Epoch 49/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.2522 - accuracy: 0.9037\n",
            "Epoch 50/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2580 - accuracy: 0.9031\n",
            "Epoch 51/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2431 - accuracy: 0.9087\n",
            "Epoch 52/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2308 - accuracy: 0.9137\n",
            "Epoch 53/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2331 - accuracy: 0.9135\n",
            "Epoch 54/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.2400 - accuracy: 0.9108\n",
            "Epoch 55/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2317 - accuracy: 0.9143\n",
            "Epoch 56/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2221 - accuracy: 0.9129\n",
            "Epoch 57/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2159 - accuracy: 0.9189\n",
            "Epoch 58/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2362 - accuracy: 0.9123\n",
            "Epoch 59/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2117 - accuracy: 0.9191\n",
            "Epoch 60/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2232 - accuracy: 0.9177\n",
            "Epoch 61/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2246 - accuracy: 0.9139\n",
            "Epoch 62/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.2107 - accuracy: 0.9249\n",
            "Epoch 63/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2123 - accuracy: 0.9227\n",
            "Epoch 64/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2122 - accuracy: 0.9215\n",
            "Epoch 65/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1994 - accuracy: 0.9285\n",
            "Epoch 66/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.1929 - accuracy: 0.9278\n",
            "Epoch 67/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1947 - accuracy: 0.9292\n",
            "Epoch 68/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1920 - accuracy: 0.9270\n",
            "Epoch 69/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1798 - accuracy: 0.9337\n",
            "Epoch 70/100\n",
            "133/133 [==============================] - 4s 26ms/step - loss: 0.2015 - accuracy: 0.9265\n",
            "Epoch 71/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1788 - accuracy: 0.9329\n",
            "Epoch 72/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1890 - accuracy: 0.9303\n",
            "Epoch 73/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1838 - accuracy: 0.9337\n",
            "Epoch 74/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.2032 - accuracy: 0.9240\n",
            "Epoch 75/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.1786 - accuracy: 0.9352\n",
            "Epoch 76/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1789 - accuracy: 0.9343\n",
            "Epoch 77/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1825 - accuracy: 0.9299\n",
            "Epoch 78/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.1832 - accuracy: 0.9330\n",
            "Epoch 79/100\n",
            "133/133 [==============================] - 4s 26ms/step - loss: 0.1885 - accuracy: 0.9325\n",
            "Epoch 80/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1835 - accuracy: 0.9375\n",
            "Epoch 81/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1835 - accuracy: 0.9348\n",
            "Epoch 82/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1860 - accuracy: 0.9307\n",
            "Epoch 83/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.1806 - accuracy: 0.9358\n",
            "Epoch 84/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1797 - accuracy: 0.9345\n",
            "Epoch 85/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1640 - accuracy: 0.9372\n",
            "Epoch 86/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1694 - accuracy: 0.9365\n",
            "Epoch 87/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1608 - accuracy: 0.9408\n",
            "Epoch 88/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1651 - accuracy: 0.9369\n",
            "Epoch 89/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1625 - accuracy: 0.9400\n",
            "Epoch 90/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1621 - accuracy: 0.9422\n",
            "Epoch 91/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.1588 - accuracy: 0.9415\n",
            "Epoch 92/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1500 - accuracy: 0.9461\n",
            "Epoch 93/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1557 - accuracy: 0.9407\n",
            "Epoch 94/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1571 - accuracy: 0.9433\n",
            "Epoch 95/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.1591 - accuracy: 0.9411\n",
            "Epoch 96/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1686 - accuracy: 0.9344\n",
            "Epoch 97/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1479 - accuracy: 0.9453\n",
            "Epoch 98/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1530 - accuracy: 0.9449\n",
            "Epoch 99/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.1342 - accuracy: 0.9541\n",
            "Epoch 100/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.1481 - accuracy: 0.9479\n",
            "0.7629796862602234\n",
            "(443,)\n",
            "(8460, 500, 22)\n",
            "Epoch 1/100\n",
            "133/133 [==============================] - 11s 35ms/step - loss: 2.0047 - accuracy: 0.2837\n",
            "Epoch 2/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 1.5614 - accuracy: 0.3423\n",
            "Epoch 3/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 1.3588 - accuracy: 0.3974\n",
            "Epoch 4/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 1.2564 - accuracy: 0.4433\n",
            "Epoch 5/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 1.1826 - accuracy: 0.4859\n",
            "Epoch 6/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 1.1307 - accuracy: 0.5177\n",
            "Epoch 7/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 1.0697 - accuracy: 0.5511\n",
            "Epoch 8/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 1.0305 - accuracy: 0.5603\n",
            "Epoch 9/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.9972 - accuracy: 0.5908\n",
            "Epoch 10/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.9461 - accuracy: 0.6135\n",
            "Epoch 11/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.8881 - accuracy: 0.6485\n",
            "Epoch 12/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.8342 - accuracy: 0.6636\n",
            "Epoch 13/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.7980 - accuracy: 0.6770\n",
            "Epoch 14/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.7370 - accuracy: 0.7131\n",
            "Epoch 15/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.7130 - accuracy: 0.7175\n",
            "Epoch 16/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.6700 - accuracy: 0.7415\n",
            "Epoch 17/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.6420 - accuracy: 0.7519\n",
            "Epoch 18/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.6105 - accuracy: 0.7630\n",
            "Epoch 19/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.5833 - accuracy: 0.7732\n",
            "Epoch 20/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.5700 - accuracy: 0.7712\n",
            "Epoch 21/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.5395 - accuracy: 0.7920\n",
            "Epoch 22/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.5200 - accuracy: 0.7979\n",
            "Epoch 23/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.4952 - accuracy: 0.8117\n",
            "Epoch 24/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.4671 - accuracy: 0.8168\n",
            "Epoch 25/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.4446 - accuracy: 0.8311\n",
            "Epoch 26/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.4349 - accuracy: 0.8358\n",
            "Epoch 27/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.4186 - accuracy: 0.8387\n",
            "Epoch 28/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.4222 - accuracy: 0.8356\n",
            "Epoch 29/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.3963 - accuracy: 0.8493\n",
            "Epoch 30/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3689 - accuracy: 0.8570\n",
            "Epoch 31/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3513 - accuracy: 0.8655\n",
            "Epoch 32/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.3489 - accuracy: 0.8706\n",
            "Epoch 33/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3287 - accuracy: 0.8746\n",
            "Epoch 34/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3482 - accuracy: 0.8688\n",
            "Epoch 35/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.3304 - accuracy: 0.8745\n",
            "Epoch 36/100\n",
            "133/133 [==============================] - 4s 34ms/step - loss: 0.3099 - accuracy: 0.8831\n",
            "Epoch 37/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3091 - accuracy: 0.8819\n",
            "Epoch 38/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.2976 - accuracy: 0.8896\n",
            "Epoch 39/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.2928 - accuracy: 0.8884\n",
            "Epoch 40/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2871 - accuracy: 0.8892\n",
            "Epoch 41/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2811 - accuracy: 0.8928\n",
            "Epoch 42/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.2659 - accuracy: 0.9018\n",
            "Epoch 43/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2551 - accuracy: 0.9032\n",
            "Epoch 44/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2536 - accuracy: 0.9045\n",
            "Epoch 45/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.2551 - accuracy: 0.9014\n",
            "Epoch 46/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2478 - accuracy: 0.9095\n",
            "Epoch 47/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2504 - accuracy: 0.9085\n",
            "Epoch 48/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.2379 - accuracy: 0.9095\n",
            "Epoch 49/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2361 - accuracy: 0.9096\n",
            "Epoch 50/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2318 - accuracy: 0.9115\n",
            "Epoch 51/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.2141 - accuracy: 0.9219\n",
            "Epoch 52/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2382 - accuracy: 0.9083\n",
            "Epoch 53/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2065 - accuracy: 0.9239\n",
            "Epoch 54/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.2085 - accuracy: 0.9222\n",
            "Epoch 55/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2084 - accuracy: 0.9221\n",
            "Epoch 56/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2087 - accuracy: 0.9230\n",
            "Epoch 57/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.2138 - accuracy: 0.9202\n",
            "Epoch 58/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2106 - accuracy: 0.9199\n",
            "Epoch 59/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1876 - accuracy: 0.9336\n",
            "Epoch 60/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1975 - accuracy: 0.9273\n",
            "Epoch 61/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1787 - accuracy: 0.9340\n",
            "Epoch 62/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1940 - accuracy: 0.9291\n",
            "Epoch 63/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1914 - accuracy: 0.9324\n",
            "Epoch 64/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1899 - accuracy: 0.9293\n",
            "Epoch 65/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1812 - accuracy: 0.9325\n",
            "Epoch 66/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1839 - accuracy: 0.9325\n",
            "Epoch 67/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1823 - accuracy: 0.9294\n",
            "Epoch 68/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1722 - accuracy: 0.9359\n",
            "Epoch 69/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1683 - accuracy: 0.9381\n",
            "Epoch 70/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1635 - accuracy: 0.9387\n",
            "Epoch 71/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1834 - accuracy: 0.9318\n",
            "Epoch 72/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1727 - accuracy: 0.9362\n",
            "Epoch 73/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1790 - accuracy: 0.9357\n",
            "Epoch 74/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1530 - accuracy: 0.9452\n",
            "Epoch 75/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1652 - accuracy: 0.9402\n",
            "Epoch 76/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.1667 - accuracy: 0.9403\n",
            "Epoch 77/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1632 - accuracy: 0.9382\n",
            "Epoch 78/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1695 - accuracy: 0.9388\n",
            "Epoch 79/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.1646 - accuracy: 0.9391\n",
            "Epoch 80/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1517 - accuracy: 0.9435\n",
            "Epoch 81/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1483 - accuracy: 0.9467\n",
            "Epoch 82/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.1610 - accuracy: 0.9424\n",
            "Epoch 83/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1596 - accuracy: 0.9420\n",
            "Epoch 84/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1485 - accuracy: 0.9431\n",
            "Epoch 85/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1463 - accuracy: 0.9475\n",
            "Epoch 86/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1618 - accuracy: 0.9398\n",
            "Epoch 87/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1385 - accuracy: 0.9476\n",
            "Epoch 88/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1541 - accuracy: 0.9439\n",
            "Epoch 89/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1285 - accuracy: 0.9507\n",
            "Epoch 90/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1461 - accuracy: 0.9481\n",
            "Epoch 91/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1543 - accuracy: 0.9439\n",
            "Epoch 92/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1619 - accuracy: 0.9405\n",
            "Epoch 93/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1435 - accuracy: 0.9488\n",
            "Epoch 94/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1320 - accuracy: 0.9559\n",
            "Epoch 95/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1343 - accuracy: 0.9513\n",
            "Epoch 96/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1505 - accuracy: 0.9423\n",
            "Epoch 97/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1268 - accuracy: 0.9526\n",
            "Epoch 98/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1530 - accuracy: 0.9478\n",
            "Epoch 99/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1339 - accuracy: 0.9496\n",
            "Epoch 100/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1289 - accuracy: 0.9538\n",
            "0.7522573471069336\n"
          ]
        }
      ],
      "source": [
        "# Compiling the model\n",
        "from tensorflow import keras\n",
        "\n",
        "time_results=np.zeros(4)\n",
        "\n",
        "for i in range(1,5):\n",
        "    \n",
        "    time_point=250*i\n",
        "    X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True,time_point)\n",
        "    x_train_valid_p = np.swapaxes(X_train_valid_prep, 2,1)\n",
        "    y_train_valid_p = to_categorical(y_train_valid_prep, 4)\n",
        "    X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True,time_point)\n",
        "    y_test_p = to_categorical(y_test_prep, 4)\n",
        "    x_test_p = np.swapaxes(X_test_prep, 2,1)\n",
        "    \n",
        "    print(y_test.shape)\n",
        "\n",
        "    print(x_train_valid_p.shape)\n",
        "    learning_rate = 1e-3\n",
        "    epochs = 100\n",
        "    decay_steps = 1000\n",
        "    cnn_optimizer = keras.optimizers.experimental.AdamW(learning_rate=learning_rate)\n",
        "\n",
        "    \n",
        "    basic_cnn_model = CNN_Transformer(intermediate_dim=6, num_heads=2, add_layer = True,time=int(time_point/2))\n",
        "    \n",
        "    basic_cnn_model.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=cnn_optimizer,\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "# Training and validating the model\n",
        "    basic_cnn_model_results = basic_cnn_model.fit(x_train_valid_p,\n",
        "                             y_train_valid_p,\n",
        "                             batch_size=64,\n",
        "                             epochs=epochs,\n",
        "                             verbose=True)\n",
        "    \n",
        "    cnn_score = basic_cnn_model.evaluate(x_test_p, y_test_p, verbose=0)[1]\n",
        "    \n",
        "    #Print the current accuracy with the specified time bins. \n",
        "\n",
        "    print(cnn_score)\n",
        "\n",
        "    time_results[i-1]=cnn_score\n",
        "\n",
        "np.save(\"cnn_transformer_timestamp_250_test_result.npy\",time_results)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (iv) Compiling the CNN+Transformer model and Training the model based on different specified time bins (750, 800, 850, 900, 950, 1000). Time = 750 has the highest accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-EfwgGN2AAP",
        "outputId": "548114a5-7445-4890-8c14-e71b72ddb980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(443,)\n",
            "(8460, 375, 22)\n",
            "Epoch 1/100\n",
            "133/133 [==============================] - 9s 24ms/step - loss: 1.9792 - accuracy: 0.2868\n",
            "Epoch 2/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 1.5156 - accuracy: 0.3469\n",
            "Epoch 3/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 1.3224 - accuracy: 0.4175\n",
            "Epoch 4/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 1.2036 - accuracy: 0.4760\n",
            "Epoch 5/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 1.1533 - accuracy: 0.4955\n",
            "Epoch 6/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 1.0873 - accuracy: 0.5346\n",
            "Epoch 7/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 1.0381 - accuracy: 0.5708\n",
            "Epoch 8/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.9821 - accuracy: 0.5963\n",
            "Epoch 9/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.9265 - accuracy: 0.6275\n",
            "Epoch 10/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.8784 - accuracy: 0.6480\n",
            "Epoch 11/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.8358 - accuracy: 0.6631\n",
            "Epoch 12/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.7913 - accuracy: 0.6861\n",
            "Epoch 13/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.7692 - accuracy: 0.6914\n",
            "Epoch 14/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.7330 - accuracy: 0.7104\n",
            "Epoch 15/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.6904 - accuracy: 0.7235\n",
            "Epoch 16/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.6603 - accuracy: 0.7460\n",
            "Epoch 17/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.6348 - accuracy: 0.7519\n",
            "Epoch 18/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.6195 - accuracy: 0.7552\n",
            "Epoch 19/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.5875 - accuracy: 0.7709\n",
            "Epoch 20/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.5650 - accuracy: 0.7793\n",
            "Epoch 21/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.5424 - accuracy: 0.7870\n",
            "Epoch 22/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.5253 - accuracy: 0.7950\n",
            "Epoch 23/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.4889 - accuracy: 0.8142\n",
            "Epoch 24/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.4915 - accuracy: 0.8156\n",
            "Epoch 25/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.4639 - accuracy: 0.8227\n",
            "Epoch 26/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.4361 - accuracy: 0.8342\n",
            "Epoch 27/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.4347 - accuracy: 0.8343\n",
            "Epoch 28/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.4179 - accuracy: 0.8407\n",
            "Epoch 29/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.4085 - accuracy: 0.8434\n",
            "Epoch 30/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.3832 - accuracy: 0.8528\n",
            "Epoch 31/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.3853 - accuracy: 0.8511\n",
            "Epoch 32/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.3622 - accuracy: 0.8606\n",
            "Epoch 33/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.3466 - accuracy: 0.8658\n",
            "Epoch 34/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.3282 - accuracy: 0.8746\n",
            "Epoch 35/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.3300 - accuracy: 0.8743\n",
            "Epoch 36/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.3309 - accuracy: 0.8708\n",
            "Epoch 37/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.3205 - accuracy: 0.8813\n",
            "Epoch 38/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.3209 - accuracy: 0.8747\n",
            "Epoch 39/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.3062 - accuracy: 0.8852\n",
            "Epoch 40/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.3039 - accuracy: 0.8861\n",
            "Epoch 41/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2897 - accuracy: 0.8930\n",
            "Epoch 42/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2793 - accuracy: 0.8969\n",
            "Epoch 43/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.2837 - accuracy: 0.8940\n",
            "Epoch 44/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.2765 - accuracy: 0.8930\n",
            "Epoch 45/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2548 - accuracy: 0.9022\n",
            "Epoch 46/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2699 - accuracy: 0.8993\n",
            "Epoch 47/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.2620 - accuracy: 0.9025\n",
            "Epoch 48/100\n",
            "133/133 [==============================] - 4s 26ms/step - loss: 0.2551 - accuracy: 0.9053\n",
            "Epoch 49/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2514 - accuracy: 0.9066\n",
            "Epoch 50/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2461 - accuracy: 0.9093\n",
            "Epoch 51/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.2387 - accuracy: 0.9106\n",
            "Epoch 52/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2383 - accuracy: 0.9154\n",
            "Epoch 53/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.2348 - accuracy: 0.9131\n",
            "Epoch 54/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.2382 - accuracy: 0.9064\n",
            "Epoch 55/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2332 - accuracy: 0.9130\n",
            "Epoch 56/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2136 - accuracy: 0.9203\n",
            "Epoch 57/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.2247 - accuracy: 0.9171\n",
            "Epoch 58/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.2179 - accuracy: 0.9197\n",
            "Epoch 59/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2133 - accuracy: 0.9222\n",
            "Epoch 60/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2150 - accuracy: 0.9180\n",
            "Epoch 61/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.1977 - accuracy: 0.9275\n",
            "Epoch 62/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2058 - accuracy: 0.9253\n",
            "Epoch 63/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2077 - accuracy: 0.9221\n",
            "Epoch 64/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2117 - accuracy: 0.9216\n",
            "Epoch 65/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.2108 - accuracy: 0.9226\n",
            "Epoch 66/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1944 - accuracy: 0.9297\n",
            "Epoch 67/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1976 - accuracy: 0.9261\n",
            "Epoch 68/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1898 - accuracy: 0.9290\n",
            "Epoch 69/100\n",
            "133/133 [==============================] - 4s 26ms/step - loss: 0.1771 - accuracy: 0.9356\n",
            "Epoch 70/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1803 - accuracy: 0.9312\n",
            "Epoch 71/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1897 - accuracy: 0.9287\n",
            "Epoch 72/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1913 - accuracy: 0.9286\n",
            "Epoch 73/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.1883 - accuracy: 0.9314\n",
            "Epoch 74/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.1799 - accuracy: 0.9338\n",
            "Epoch 75/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1785 - accuracy: 0.9329\n",
            "Epoch 76/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1687 - accuracy: 0.9390\n",
            "Epoch 77/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1675 - accuracy: 0.9384\n",
            "Epoch 78/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.1804 - accuracy: 0.9346\n",
            "Epoch 79/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1721 - accuracy: 0.9369\n",
            "Epoch 80/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1734 - accuracy: 0.9383\n",
            "Epoch 81/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1786 - accuracy: 0.9346\n",
            "Epoch 82/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.1818 - accuracy: 0.9344\n",
            "Epoch 83/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1779 - accuracy: 0.9353\n",
            "Epoch 84/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1711 - accuracy: 0.9371\n",
            "Epoch 85/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1626 - accuracy: 0.9398\n",
            "Epoch 86/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1635 - accuracy: 0.9400\n",
            "Epoch 87/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1554 - accuracy: 0.9422\n",
            "Epoch 88/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1611 - accuracy: 0.9416\n",
            "Epoch 89/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1523 - accuracy: 0.9460\n",
            "Epoch 90/100\n",
            "133/133 [==============================] - 4s 27ms/step - loss: 0.1843 - accuracy: 0.9332\n",
            "Epoch 91/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1455 - accuracy: 0.9469\n",
            "Epoch 92/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1607 - accuracy: 0.9427\n",
            "Epoch 93/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1550 - accuracy: 0.9430\n",
            "Epoch 94/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.1519 - accuracy: 0.9430\n",
            "Epoch 95/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1573 - accuracy: 0.9415\n",
            "Epoch 96/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1508 - accuracy: 0.9456\n",
            "Epoch 97/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.1535 - accuracy: 0.9442\n",
            "Epoch 98/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1584 - accuracy: 0.9409\n",
            "Epoch 99/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.1521 - accuracy: 0.9448\n",
            "Epoch 100/100\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 0.1556 - accuracy: 0.9440\n",
            "0.7590293288230896\n",
            "(443,)\n",
            "(8460, 400, 22)\n",
            "Epoch 1/100\n",
            "133/133 [==============================] - 10s 31ms/step - loss: 1.9855 - accuracy: 0.2929\n",
            "Epoch 2/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 1.5115 - accuracy: 0.3565\n",
            "Epoch 3/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 1.3183 - accuracy: 0.4193\n",
            "Epoch 4/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 1.2214 - accuracy: 0.4572\n",
            "Epoch 5/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 1.1605 - accuracy: 0.4987\n",
            "Epoch 6/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 1.0900 - accuracy: 0.5355\n",
            "Epoch 7/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 1.0425 - accuracy: 0.5606\n",
            "Epoch 8/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.9984 - accuracy: 0.5803\n",
            "Epoch 9/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.9390 - accuracy: 0.6125\n",
            "Epoch 10/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.8935 - accuracy: 0.6410\n",
            "Epoch 11/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.8396 - accuracy: 0.6592\n",
            "Epoch 12/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.7915 - accuracy: 0.6850\n",
            "Epoch 13/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.7707 - accuracy: 0.6940\n",
            "Epoch 14/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.7244 - accuracy: 0.7129\n",
            "Epoch 15/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.6962 - accuracy: 0.7234\n",
            "Epoch 16/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.6710 - accuracy: 0.7408\n",
            "Epoch 17/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.6388 - accuracy: 0.7482\n",
            "Epoch 18/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.6121 - accuracy: 0.7628\n",
            "Epoch 19/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.6026 - accuracy: 0.7629\n",
            "Epoch 20/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.5752 - accuracy: 0.7759\n",
            "Epoch 21/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.5514 - accuracy: 0.7864\n",
            "Epoch 22/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.5384 - accuracy: 0.7933\n",
            "Epoch 23/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.5038 - accuracy: 0.8005\n",
            "Epoch 24/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.4839 - accuracy: 0.8149\n",
            "Epoch 25/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.4791 - accuracy: 0.8137\n",
            "Epoch 26/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.4361 - accuracy: 0.8348\n",
            "Epoch 27/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.4319 - accuracy: 0.8355\n",
            "Epoch 28/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.4249 - accuracy: 0.8356\n",
            "Epoch 29/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.4036 - accuracy: 0.8486\n",
            "Epoch 30/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.3976 - accuracy: 0.8449\n",
            "Epoch 31/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.3693 - accuracy: 0.8606\n",
            "Epoch 32/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.3622 - accuracy: 0.8605\n",
            "Epoch 33/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.3427 - accuracy: 0.8722\n",
            "Epoch 34/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.3488 - accuracy: 0.8669\n",
            "Epoch 35/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.3268 - accuracy: 0.8765\n",
            "Epoch 36/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.3274 - accuracy: 0.8779\n",
            "Epoch 37/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.3142 - accuracy: 0.8831\n",
            "Epoch 38/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.3041 - accuracy: 0.8878\n",
            "Epoch 39/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.3026 - accuracy: 0.8832\n",
            "Epoch 40/100\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 0.2885 - accuracy: 0.8891\n",
            "Epoch 41/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2781 - accuracy: 0.8967\n",
            "Epoch 42/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.2834 - accuracy: 0.8907\n",
            "Epoch 43/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2674 - accuracy: 0.8980\n",
            "Epoch 44/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2524 - accuracy: 0.9063\n",
            "Epoch 45/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2573 - accuracy: 0.9018\n",
            "Epoch 46/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.2644 - accuracy: 0.9018\n",
            "Epoch 47/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2326 - accuracy: 0.9104\n",
            "Epoch 48/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2471 - accuracy: 0.9106\n",
            "Epoch 49/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2449 - accuracy: 0.9077\n",
            "Epoch 50/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.2321 - accuracy: 0.9123\n",
            "Epoch 51/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2455 - accuracy: 0.9098\n",
            "Epoch 52/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2553 - accuracy: 0.9028\n",
            "Epoch 53/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2385 - accuracy: 0.9077\n",
            "Epoch 54/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2378 - accuracy: 0.9151\n",
            "Epoch 55/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2191 - accuracy: 0.9158\n",
            "Epoch 56/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2240 - accuracy: 0.9187\n",
            "Epoch 57/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.2153 - accuracy: 0.9210\n",
            "Epoch 58/100\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 0.2009 - accuracy: 0.9242\n",
            "Epoch 59/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2127 - accuracy: 0.9247\n",
            "Epoch 60/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1960 - accuracy: 0.9288\n",
            "Epoch 61/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.2150 - accuracy: 0.9203\n",
            "Epoch 62/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.2153 - accuracy: 0.9182\n",
            "Epoch 63/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1979 - accuracy: 0.9278\n",
            "Epoch 64/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1881 - accuracy: 0.9311\n",
            "Epoch 65/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1932 - accuracy: 0.9309\n",
            "Epoch 66/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1972 - accuracy: 0.9294\n",
            "Epoch 67/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1995 - accuracy: 0.9249\n",
            "Epoch 68/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1870 - accuracy: 0.9317\n",
            "Epoch 69/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1805 - accuracy: 0.9311\n",
            "Epoch 70/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1743 - accuracy: 0.9375\n",
            "Epoch 71/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1938 - accuracy: 0.9286\n",
            "Epoch 72/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1843 - accuracy: 0.9301\n",
            "Epoch 73/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1769 - accuracy: 0.9362\n",
            "Epoch 74/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1806 - accuracy: 0.9306\n",
            "Epoch 75/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1766 - accuracy: 0.9356\n",
            "Epoch 76/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1598 - accuracy: 0.9409\n",
            "Epoch 77/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1781 - accuracy: 0.9333\n",
            "Epoch 78/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1760 - accuracy: 0.9333\n",
            "Epoch 79/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1821 - accuracy: 0.9316\n",
            "Epoch 80/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1654 - accuracy: 0.9375\n",
            "Epoch 81/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1660 - accuracy: 0.9389\n",
            "Epoch 82/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1808 - accuracy: 0.9340\n",
            "Epoch 83/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1734 - accuracy: 0.9375\n",
            "Epoch 84/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1712 - accuracy: 0.9356\n",
            "Epoch 85/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1604 - accuracy: 0.9413\n",
            "Epoch 86/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1624 - accuracy: 0.9394\n",
            "Epoch 87/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1467 - accuracy: 0.9454\n",
            "Epoch 88/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1642 - accuracy: 0.9391\n",
            "Epoch 89/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1617 - accuracy: 0.9444\n",
            "Epoch 90/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1619 - accuracy: 0.9421\n",
            "Epoch 91/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1503 - accuracy: 0.9437\n",
            "Epoch 92/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1568 - accuracy: 0.9452\n",
            "Epoch 93/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1599 - accuracy: 0.9417\n",
            "Epoch 94/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1533 - accuracy: 0.9431\n",
            "Epoch 95/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1628 - accuracy: 0.9421\n",
            "Epoch 96/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1582 - accuracy: 0.9426\n",
            "Epoch 97/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1512 - accuracy: 0.9443\n",
            "Epoch 98/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1475 - accuracy: 0.9466\n",
            "Epoch 99/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1548 - accuracy: 0.9452\n",
            "Epoch 100/100\n",
            "133/133 [==============================] - 3s 25ms/step - loss: 0.1520 - accuracy: 0.9436\n",
            "0.7358916401863098\n",
            "(443,)\n",
            "(8460, 425, 22)\n",
            "Epoch 1/100\n",
            "133/133 [==============================] - 12s 34ms/step - loss: 2.0016 - accuracy: 0.2946\n",
            "Epoch 2/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 1.5138 - accuracy: 0.3681\n",
            "Epoch 3/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 1.3392 - accuracy: 0.3999\n",
            "Epoch 4/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 1.2229 - accuracy: 0.4567\n",
            "Epoch 5/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 1.1463 - accuracy: 0.5084\n",
            "Epoch 6/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 1.1021 - accuracy: 0.5345\n",
            "Epoch 7/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 1.0575 - accuracy: 0.5553\n",
            "Epoch 8/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 1.0088 - accuracy: 0.5862\n",
            "Epoch 9/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.9501 - accuracy: 0.6164\n",
            "Epoch 10/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.8987 - accuracy: 0.6314\n",
            "Epoch 11/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.8483 - accuracy: 0.6610\n",
            "Epoch 12/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.7999 - accuracy: 0.6823\n",
            "Epoch 13/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.7616 - accuracy: 0.6959\n",
            "Epoch 14/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.7297 - accuracy: 0.7130\n",
            "Epoch 15/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.7141 - accuracy: 0.7175\n",
            "Epoch 16/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.6791 - accuracy: 0.7314\n",
            "Epoch 17/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.6426 - accuracy: 0.7508\n",
            "Epoch 18/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.6216 - accuracy: 0.7535\n",
            "Epoch 19/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.5845 - accuracy: 0.7703\n",
            "Epoch 20/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.5632 - accuracy: 0.7831\n",
            "Epoch 21/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.5417 - accuracy: 0.7909\n",
            "Epoch 22/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.5108 - accuracy: 0.8054\n",
            "Epoch 23/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.4939 - accuracy: 0.8090\n",
            "Epoch 24/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.4739 - accuracy: 0.8167\n",
            "Epoch 25/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.4641 - accuracy: 0.8201\n",
            "Epoch 26/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.4408 - accuracy: 0.8303\n",
            "Epoch 27/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.4239 - accuracy: 0.8372\n",
            "Epoch 28/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.4226 - accuracy: 0.8410\n",
            "Epoch 29/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.4080 - accuracy: 0.8396\n",
            "Epoch 30/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.3820 - accuracy: 0.8491\n",
            "Epoch 31/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.3617 - accuracy: 0.8619\n",
            "Epoch 32/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.3546 - accuracy: 0.8655\n",
            "Epoch 33/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.3409 - accuracy: 0.8725\n",
            "Epoch 34/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.3381 - accuracy: 0.8714\n",
            "Epoch 35/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.3214 - accuracy: 0.8774\n",
            "Epoch 36/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.3063 - accuracy: 0.8819\n",
            "Epoch 37/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.3156 - accuracy: 0.8837\n",
            "Epoch 38/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.3076 - accuracy: 0.8827\n",
            "Epoch 39/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.3036 - accuracy: 0.8871\n",
            "Epoch 40/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.2941 - accuracy: 0.8911\n",
            "Epoch 41/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2894 - accuracy: 0.8921\n",
            "Epoch 42/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2738 - accuracy: 0.8980\n",
            "Epoch 43/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.2739 - accuracy: 0.8930\n",
            "Epoch 44/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2657 - accuracy: 0.9017\n",
            "Epoch 45/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2579 - accuracy: 0.9050\n",
            "Epoch 46/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.2499 - accuracy: 0.9065\n",
            "Epoch 47/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.2461 - accuracy: 0.9072\n",
            "Epoch 48/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2363 - accuracy: 0.9115\n",
            "Epoch 49/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2402 - accuracy: 0.9106\n",
            "Epoch 50/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.2205 - accuracy: 0.9206\n",
            "Epoch 51/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.2274 - accuracy: 0.9128\n",
            "Epoch 52/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2231 - accuracy: 0.9176\n",
            "Epoch 53/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2142 - accuracy: 0.9239\n",
            "Epoch 54/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.2214 - accuracy: 0.9176\n",
            "Epoch 55/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2260 - accuracy: 0.9182\n",
            "Epoch 56/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2095 - accuracy: 0.9206\n",
            "Epoch 57/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.2084 - accuracy: 0.9229\n",
            "Epoch 58/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.2167 - accuracy: 0.9186\n",
            "Epoch 59/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.2127 - accuracy: 0.9215\n",
            "Epoch 60/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.2095 - accuracy: 0.9254\n",
            "Epoch 61/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1919 - accuracy: 0.9286\n",
            "Epoch 62/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1981 - accuracy: 0.9229\n",
            "Epoch 63/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1887 - accuracy: 0.9290\n",
            "Epoch 64/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1971 - accuracy: 0.9252\n",
            "Epoch 65/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1823 - accuracy: 0.9318\n",
            "Epoch 66/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1836 - accuracy: 0.9342\n",
            "Epoch 67/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1882 - accuracy: 0.9305\n",
            "Epoch 68/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.1844 - accuracy: 0.9300\n",
            "Epoch 69/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1846 - accuracy: 0.9306\n",
            "Epoch 70/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1811 - accuracy: 0.9335\n",
            "Epoch 71/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1916 - accuracy: 0.9281\n",
            "Epoch 72/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1712 - accuracy: 0.9384\n",
            "Epoch 73/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1797 - accuracy: 0.9327\n",
            "Epoch 74/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1658 - accuracy: 0.9409\n",
            "Epoch 75/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1599 - accuracy: 0.9417\n",
            "Epoch 76/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1648 - accuracy: 0.9384\n",
            "Epoch 77/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1787 - accuracy: 0.9356\n",
            "Epoch 78/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1604 - accuracy: 0.9402\n",
            "Epoch 79/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1468 - accuracy: 0.9478\n",
            "Epoch 80/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1627 - accuracy: 0.9416\n",
            "Epoch 81/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1588 - accuracy: 0.9400\n",
            "Epoch 82/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1681 - accuracy: 0.9389\n",
            "Epoch 83/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1569 - accuracy: 0.9396\n",
            "Epoch 84/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1623 - accuracy: 0.9407\n",
            "Epoch 85/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1594 - accuracy: 0.9409\n",
            "Epoch 86/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1592 - accuracy: 0.9431\n",
            "Epoch 87/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1505 - accuracy: 0.9447\n",
            "Epoch 88/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1495 - accuracy: 0.9434\n",
            "Epoch 89/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1513 - accuracy: 0.9452\n",
            "Epoch 90/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1519 - accuracy: 0.9434\n",
            "Epoch 91/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1384 - accuracy: 0.9473\n",
            "Epoch 92/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1382 - accuracy: 0.9499\n",
            "Epoch 93/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1577 - accuracy: 0.9413\n",
            "Epoch 94/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1539 - accuracy: 0.9465\n",
            "Epoch 95/100\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 0.1492 - accuracy: 0.9455\n",
            "Epoch 96/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1413 - accuracy: 0.9473\n",
            "Epoch 97/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1468 - accuracy: 0.9474\n",
            "Epoch 98/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1482 - accuracy: 0.9482\n",
            "Epoch 99/100\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 0.1514 - accuracy: 0.9485\n",
            "Epoch 100/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.1472 - accuracy: 0.9481\n",
            "0.752821683883667\n",
            "(443,)\n",
            "(8460, 450, 22)\n",
            "Epoch 1/100\n",
            "133/133 [==============================] - 12s 34ms/step - loss: 1.9515 - accuracy: 0.3006\n",
            "Epoch 2/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 1.5092 - accuracy: 0.3606\n",
            "Epoch 3/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 1.3169 - accuracy: 0.4227\n",
            "Epoch 4/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 1.2194 - accuracy: 0.4680\n",
            "Epoch 5/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 1.1567 - accuracy: 0.4995\n",
            "Epoch 6/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 1.1100 - accuracy: 0.5254\n",
            "Epoch 7/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 1.0669 - accuracy: 0.5454\n",
            "Epoch 8/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 1.0227 - accuracy: 0.5703\n",
            "Epoch 9/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.9621 - accuracy: 0.6026\n",
            "Epoch 10/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.9067 - accuracy: 0.6350\n",
            "Epoch 11/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.8504 - accuracy: 0.6591\n",
            "Epoch 12/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.8168 - accuracy: 0.6697\n",
            "Epoch 13/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.7812 - accuracy: 0.6896\n",
            "Epoch 14/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.7444 - accuracy: 0.7033\n",
            "Epoch 15/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.7021 - accuracy: 0.7298\n",
            "Epoch 16/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.6876 - accuracy: 0.7343\n",
            "Epoch 17/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.6539 - accuracy: 0.7431\n",
            "Epoch 18/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.6440 - accuracy: 0.7517\n",
            "Epoch 19/100\n",
            "133/133 [==============================] - 4s 34ms/step - loss: 0.5983 - accuracy: 0.7680\n",
            "Epoch 20/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.5872 - accuracy: 0.7745\n",
            "Epoch 21/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.5586 - accuracy: 0.7816\n",
            "Epoch 22/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.5333 - accuracy: 0.7952\n",
            "Epoch 23/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.5005 - accuracy: 0.8002\n",
            "Epoch 24/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.4918 - accuracy: 0.8070\n",
            "Epoch 25/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.4557 - accuracy: 0.8266\n",
            "Epoch 26/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.4536 - accuracy: 0.8271\n",
            "Epoch 27/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.4572 - accuracy: 0.8216\n",
            "Epoch 28/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.4258 - accuracy: 0.8327\n",
            "Epoch 29/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.4053 - accuracy: 0.8408\n",
            "Epoch 30/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.4007 - accuracy: 0.8487\n",
            "Epoch 31/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.3769 - accuracy: 0.8507\n",
            "Epoch 32/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.3824 - accuracy: 0.8522\n",
            "Epoch 33/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.3467 - accuracy: 0.8686\n",
            "Epoch 34/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.3585 - accuracy: 0.8651\n",
            "Epoch 35/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.3440 - accuracy: 0.8702\n",
            "Epoch 36/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.3258 - accuracy: 0.8772\n",
            "Epoch 37/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.3107 - accuracy: 0.8827\n",
            "Epoch 38/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.3100 - accuracy: 0.8868\n",
            "Epoch 39/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.3068 - accuracy: 0.8858\n",
            "Epoch 40/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.3066 - accuracy: 0.8836\n",
            "Epoch 41/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.3036 - accuracy: 0.8850\n",
            "Epoch 42/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2721 - accuracy: 0.8947\n",
            "Epoch 43/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.2707 - accuracy: 0.9005\n",
            "Epoch 44/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.2634 - accuracy: 0.9009\n",
            "Epoch 45/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.2865 - accuracy: 0.8931\n",
            "Epoch 46/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.2536 - accuracy: 0.9085\n",
            "Epoch 47/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.2617 - accuracy: 0.9009\n",
            "Epoch 48/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.2545 - accuracy: 0.9031\n",
            "Epoch 49/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2500 - accuracy: 0.9052\n",
            "Epoch 50/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.2320 - accuracy: 0.9121\n",
            "Epoch 51/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.2472 - accuracy: 0.9091\n",
            "Epoch 52/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.2430 - accuracy: 0.9056\n",
            "Epoch 53/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.2203 - accuracy: 0.9196\n",
            "Epoch 54/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.2313 - accuracy: 0.9144\n",
            "Epoch 55/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.2226 - accuracy: 0.9202\n",
            "Epoch 56/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.2258 - accuracy: 0.9173\n",
            "Epoch 57/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.2171 - accuracy: 0.9194\n",
            "Epoch 58/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.2135 - accuracy: 0.9196\n",
            "Epoch 59/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2331 - accuracy: 0.9124\n",
            "Epoch 60/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.2189 - accuracy: 0.9173\n",
            "Epoch 61/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1938 - accuracy: 0.9280\n",
            "Epoch 62/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2006 - accuracy: 0.9278\n",
            "Epoch 63/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1941 - accuracy: 0.9251\n",
            "Epoch 64/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1959 - accuracy: 0.9312\n",
            "Epoch 65/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.1866 - accuracy: 0.9322\n",
            "Epoch 66/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.2009 - accuracy: 0.9277\n",
            "Epoch 67/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1958 - accuracy: 0.9277\n",
            "Epoch 68/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.2049 - accuracy: 0.9228\n",
            "Epoch 69/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1949 - accuracy: 0.9288\n",
            "Epoch 70/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1907 - accuracy: 0.9285\n",
            "Epoch 71/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1799 - accuracy: 0.9319\n",
            "Epoch 72/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1879 - accuracy: 0.9299\n",
            "Epoch 73/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.2039 - accuracy: 0.9257\n",
            "Epoch 74/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1877 - accuracy: 0.9324\n",
            "Epoch 75/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.1731 - accuracy: 0.9374\n",
            "Epoch 76/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.1748 - accuracy: 0.9383\n",
            "Epoch 77/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1711 - accuracy: 0.9353\n",
            "Epoch 78/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1610 - accuracy: 0.9407\n",
            "Epoch 79/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1790 - accuracy: 0.9362\n",
            "Epoch 80/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1709 - accuracy: 0.9394\n",
            "Epoch 81/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1724 - accuracy: 0.9364\n",
            "Epoch 82/100\n",
            "133/133 [==============================] - 4s 34ms/step - loss: 0.1680 - accuracy: 0.9368\n",
            "Epoch 83/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1791 - accuracy: 0.9357\n",
            "Epoch 84/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1535 - accuracy: 0.9428\n",
            "Epoch 85/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.1688 - accuracy: 0.9371\n",
            "Epoch 86/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1557 - accuracy: 0.9417\n",
            "Epoch 87/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1574 - accuracy: 0.9442\n",
            "Epoch 88/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1685 - accuracy: 0.9371\n",
            "Epoch 89/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.1528 - accuracy: 0.9430\n",
            "Epoch 90/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1548 - accuracy: 0.9409\n",
            "Epoch 91/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1597 - accuracy: 0.9413\n",
            "Epoch 92/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1567 - accuracy: 0.9427\n",
            "Epoch 93/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1702 - accuracy: 0.9374\n",
            "Epoch 94/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1522 - accuracy: 0.9424\n",
            "Epoch 95/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1509 - accuracy: 0.9439\n",
            "Epoch 96/100\n",
            "133/133 [==============================] - 4s 31ms/step - loss: 0.1544 - accuracy: 0.9437\n",
            "Epoch 97/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1612 - accuracy: 0.9396\n",
            "Epoch 98/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.1478 - accuracy: 0.9434\n",
            "Epoch 99/100\n",
            "133/133 [==============================] - 4s 32ms/step - loss: 0.1421 - accuracy: 0.9480\n",
            "Epoch 100/100\n",
            "133/133 [==============================] - 4s 30ms/step - loss: 0.1550 - accuracy: 0.9450\n",
            "0.7511286735534668\n",
            "(443,)\n",
            "(8460, 475, 22)\n",
            "Epoch 1/100\n",
            "133/133 [==============================] - 11s 37ms/step - loss: 1.9942 - accuracy: 0.2974\n",
            "Epoch 2/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 1.5066 - accuracy: 0.3735\n",
            "Epoch 3/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 1.2948 - accuracy: 0.4369\n",
            "Epoch 4/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 1.2052 - accuracy: 0.4727\n",
            "Epoch 5/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 1.1319 - accuracy: 0.5117\n",
            "Epoch 6/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 1.0941 - accuracy: 0.5371\n",
            "Epoch 7/100\n",
            "133/133 [==============================] - 4s 34ms/step - loss: 1.0450 - accuracy: 0.5590\n",
            "Epoch 8/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.9900 - accuracy: 0.5956\n",
            "Epoch 9/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.9303 - accuracy: 0.6167\n",
            "Epoch 10/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.8623 - accuracy: 0.6508\n",
            "Epoch 11/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.8151 - accuracy: 0.6746\n",
            "Epoch 12/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.8028 - accuracy: 0.6842\n",
            "Epoch 13/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.7482 - accuracy: 0.7044\n",
            "Epoch 14/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.7129 - accuracy: 0.7245\n",
            "Epoch 15/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.6782 - accuracy: 0.7378\n",
            "Epoch 16/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.6697 - accuracy: 0.7421\n",
            "Epoch 17/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.6231 - accuracy: 0.7548\n",
            "Epoch 18/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.5956 - accuracy: 0.7674\n",
            "Epoch 19/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.5656 - accuracy: 0.7827\n",
            "Epoch 20/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.5488 - accuracy: 0.7869\n",
            "Epoch 21/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.5255 - accuracy: 0.7982\n",
            "Epoch 22/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.4921 - accuracy: 0.8131\n",
            "Epoch 23/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.4864 - accuracy: 0.8125\n",
            "Epoch 24/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.4586 - accuracy: 0.8236\n",
            "Epoch 25/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.4273 - accuracy: 0.8346\n",
            "Epoch 26/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.4348 - accuracy: 0.8313\n",
            "Epoch 27/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.4166 - accuracy: 0.8410\n",
            "Epoch 28/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.4001 - accuracy: 0.8449\n",
            "Epoch 29/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.3791 - accuracy: 0.8552\n",
            "Epoch 30/100\n",
            "133/133 [==============================] - 4s 34ms/step - loss: 0.3921 - accuracy: 0.8518\n",
            "Epoch 31/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.3578 - accuracy: 0.8603\n",
            "Epoch 32/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3568 - accuracy: 0.8650\n",
            "Epoch 33/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3476 - accuracy: 0.8647\n",
            "Epoch 34/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.3385 - accuracy: 0.8714\n",
            "Epoch 35/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3272 - accuracy: 0.8800\n",
            "Epoch 36/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3179 - accuracy: 0.8780\n",
            "Epoch 37/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.3075 - accuracy: 0.8887\n",
            "Epoch 38/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3000 - accuracy: 0.8896\n",
            "Epoch 39/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.2927 - accuracy: 0.8883\n",
            "Epoch 40/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2902 - accuracy: 0.8902\n",
            "Epoch 41/100\n",
            "133/133 [==============================] - 4s 34ms/step - loss: 0.2742 - accuracy: 0.8982\n",
            "Epoch 42/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.2714 - accuracy: 0.8983\n",
            "Epoch 43/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2602 - accuracy: 0.9039\n",
            "Epoch 44/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2642 - accuracy: 0.9002\n",
            "Epoch 45/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.2479 - accuracy: 0.9093\n",
            "Epoch 46/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2537 - accuracy: 0.9080\n",
            "Epoch 47/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2579 - accuracy: 0.8996\n",
            "Epoch 48/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2462 - accuracy: 0.9026\n",
            "Epoch 49/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2372 - accuracy: 0.9105\n",
            "Epoch 50/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2308 - accuracy: 0.9142\n",
            "Epoch 51/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2427 - accuracy: 0.9077\n",
            "Epoch 52/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2247 - accuracy: 0.9161\n",
            "Epoch 53/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2222 - accuracy: 0.9152\n",
            "Epoch 54/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2281 - accuracy: 0.9132\n",
            "Epoch 55/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2179 - accuracy: 0.9182\n",
            "Epoch 56/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2109 - accuracy: 0.9219\n",
            "Epoch 57/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2164 - accuracy: 0.9174\n",
            "Epoch 58/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2163 - accuracy: 0.9167\n",
            "Epoch 59/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2193 - accuracy: 0.9190\n",
            "Epoch 60/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2065 - accuracy: 0.9209\n",
            "Epoch 61/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.2024 - accuracy: 0.9285\n",
            "Epoch 62/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1932 - accuracy: 0.9307\n",
            "Epoch 63/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1862 - accuracy: 0.9303\n",
            "Epoch 64/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1951 - accuracy: 0.9280\n",
            "Epoch 65/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1792 - accuracy: 0.9337\n",
            "Epoch 66/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1903 - accuracy: 0.9297\n",
            "Epoch 67/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1866 - accuracy: 0.9301\n",
            "Epoch 68/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1911 - accuracy: 0.9325\n",
            "Epoch 69/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1884 - accuracy: 0.9343\n",
            "Epoch 70/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1813 - accuracy: 0.9311\n",
            "Epoch 71/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1933 - accuracy: 0.9279\n",
            "Epoch 72/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1820 - accuracy: 0.9344\n",
            "Epoch 73/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1689 - accuracy: 0.9385\n",
            "Epoch 74/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1754 - accuracy: 0.9349\n",
            "Epoch 75/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1697 - accuracy: 0.9364\n",
            "Epoch 76/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1675 - accuracy: 0.9411\n",
            "Epoch 77/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1764 - accuracy: 0.9366\n",
            "Epoch 78/100\n",
            "133/133 [==============================] - 4s 34ms/step - loss: 0.1743 - accuracy: 0.9353\n",
            "Epoch 79/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.1797 - accuracy: 0.9350\n",
            "Epoch 80/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1675 - accuracy: 0.9379\n",
            "Epoch 81/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1752 - accuracy: 0.9344\n",
            "Epoch 82/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1721 - accuracy: 0.9376\n",
            "Epoch 83/100\n",
            "133/133 [==============================] - 4s 34ms/step - loss: 0.1548 - accuracy: 0.9396\n",
            "Epoch 84/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1643 - accuracy: 0.9396\n",
            "Epoch 85/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1593 - accuracy: 0.9430\n",
            "Epoch 86/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1728 - accuracy: 0.9374\n",
            "Epoch 87/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1574 - accuracy: 0.9420\n",
            "Epoch 88/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1549 - accuracy: 0.9434\n",
            "Epoch 89/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1667 - accuracy: 0.9414\n",
            "Epoch 90/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1642 - accuracy: 0.9392\n",
            "Epoch 91/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1602 - accuracy: 0.9414\n",
            "Epoch 92/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1559 - accuracy: 0.9433\n",
            "Epoch 93/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1538 - accuracy: 0.9446\n",
            "Epoch 94/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1491 - accuracy: 0.9453\n",
            "Epoch 95/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1483 - accuracy: 0.9468\n",
            "Epoch 96/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1526 - accuracy: 0.9467\n",
            "Epoch 97/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1520 - accuracy: 0.9441\n",
            "Epoch 98/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1391 - accuracy: 0.9476\n",
            "Epoch 99/100\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 0.1489 - accuracy: 0.9465\n",
            "Epoch 100/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1431 - accuracy: 0.9473\n",
            "0.755643367767334\n",
            "(443,)\n",
            "(8460, 500, 22)\n",
            "Epoch 1/100\n",
            "133/133 [==============================] - 11s 35ms/step - loss: 1.9857 - accuracy: 0.2965\n",
            "Epoch 2/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 1.5447 - accuracy: 0.3578\n",
            "Epoch 3/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 1.3562 - accuracy: 0.3996\n",
            "Epoch 4/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 1.2467 - accuracy: 0.4504\n",
            "Epoch 5/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 1.1721 - accuracy: 0.4878\n",
            "Epoch 6/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 1.1256 - accuracy: 0.5208\n",
            "Epoch 7/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 1.0708 - accuracy: 0.5430\n",
            "Epoch 8/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 1.0203 - accuracy: 0.5784\n",
            "Epoch 9/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.9654 - accuracy: 0.6037\n",
            "Epoch 10/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.9283 - accuracy: 0.6216\n",
            "Epoch 11/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.8623 - accuracy: 0.6501\n",
            "Epoch 12/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.8377 - accuracy: 0.6631\n",
            "Epoch 13/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.7894 - accuracy: 0.6851\n",
            "Epoch 14/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.7448 - accuracy: 0.7048\n",
            "Epoch 15/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.7049 - accuracy: 0.7246\n",
            "Epoch 16/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.6792 - accuracy: 0.7365\n",
            "Epoch 17/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.6380 - accuracy: 0.7495\n",
            "Epoch 18/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.6153 - accuracy: 0.7569\n",
            "Epoch 19/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.5936 - accuracy: 0.7709\n",
            "Epoch 20/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.5568 - accuracy: 0.7800\n",
            "Epoch 21/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.5385 - accuracy: 0.7857\n",
            "Epoch 22/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.5197 - accuracy: 0.7961\n",
            "Epoch 23/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.5110 - accuracy: 0.8047\n",
            "Epoch 24/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.4631 - accuracy: 0.8216\n",
            "Epoch 25/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.4616 - accuracy: 0.8191\n",
            "Epoch 26/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.4428 - accuracy: 0.8257\n",
            "Epoch 27/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.4285 - accuracy: 0.8392\n",
            "Epoch 28/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.4071 - accuracy: 0.8436\n",
            "Epoch 29/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.3842 - accuracy: 0.8544\n",
            "Epoch 30/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3811 - accuracy: 0.8550\n",
            "Epoch 31/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.3672 - accuracy: 0.8603\n",
            "Epoch 32/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.3630 - accuracy: 0.8626\n",
            "Epoch 33/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.3286 - accuracy: 0.8729\n",
            "Epoch 34/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.3361 - accuracy: 0.8758\n",
            "Epoch 35/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.3201 - accuracy: 0.8759\n",
            "Epoch 36/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.3131 - accuracy: 0.8853\n",
            "Epoch 37/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.3084 - accuracy: 0.8862\n",
            "Epoch 38/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.3053 - accuracy: 0.8822\n",
            "Epoch 39/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2921 - accuracy: 0.8868\n",
            "Epoch 40/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2758 - accuracy: 0.8972\n",
            "Epoch 41/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.2664 - accuracy: 0.8995\n",
            "Epoch 42/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2742 - accuracy: 0.8975\n",
            "Epoch 43/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2534 - accuracy: 0.9034\n",
            "Epoch 44/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.2620 - accuracy: 0.9043\n",
            "Epoch 45/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2587 - accuracy: 0.9015\n",
            "Epoch 46/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2639 - accuracy: 0.9012\n",
            "Epoch 47/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2227 - accuracy: 0.9151\n",
            "Epoch 48/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2375 - accuracy: 0.9123\n",
            "Epoch 49/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2310 - accuracy: 0.9135\n",
            "Epoch 50/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2232 - accuracy: 0.9171\n",
            "Epoch 51/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2274 - accuracy: 0.9155\n",
            "Epoch 52/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2290 - accuracy: 0.9148\n",
            "Epoch 53/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2243 - accuracy: 0.9184\n",
            "Epoch 54/100\n",
            "133/133 [==============================] - 5s 34ms/step - loss: 0.2133 - accuracy: 0.9219\n",
            "Epoch 55/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2140 - accuracy: 0.9234\n",
            "Epoch 56/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2048 - accuracy: 0.9249\n",
            "Epoch 57/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1999 - accuracy: 0.9253\n",
            "Epoch 58/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2023 - accuracy: 0.9240\n",
            "Epoch 59/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.2103 - accuracy: 0.9234\n",
            "Epoch 60/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1934 - accuracy: 0.9287\n",
            "Epoch 61/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.1987 - accuracy: 0.9271\n",
            "Epoch 62/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.2058 - accuracy: 0.9258\n",
            "Epoch 63/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1840 - accuracy: 0.9314\n",
            "Epoch 64/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1823 - accuracy: 0.9318\n",
            "Epoch 65/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1723 - accuracy: 0.9342\n",
            "Epoch 66/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1810 - accuracy: 0.9317\n",
            "Epoch 67/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1790 - accuracy: 0.9348\n",
            "Epoch 68/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1708 - accuracy: 0.9362\n",
            "Epoch 69/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1768 - accuracy: 0.9366\n",
            "Epoch 70/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.1766 - accuracy: 0.9340\n",
            "Epoch 71/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1604 - accuracy: 0.9418\n",
            "Epoch 72/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1590 - accuracy: 0.9414\n",
            "Epoch 73/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1705 - accuracy: 0.9355\n",
            "Epoch 74/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1715 - accuracy: 0.9402\n",
            "Epoch 75/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1671 - accuracy: 0.9389\n",
            "Epoch 76/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.1738 - accuracy: 0.9337\n",
            "Epoch 77/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1546 - accuracy: 0.9459\n",
            "Epoch 78/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1579 - accuracy: 0.9411\n",
            "Epoch 79/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.1557 - accuracy: 0.9429\n",
            "Epoch 80/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1628 - accuracy: 0.9405\n",
            "Epoch 81/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1662 - accuracy: 0.9398\n",
            "Epoch 82/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.1582 - accuracy: 0.9434\n",
            "Epoch 83/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1551 - accuracy: 0.9446\n",
            "Epoch 84/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1462 - accuracy: 0.9461\n",
            "Epoch 85/100\n",
            "133/133 [==============================] - 5s 37ms/step - loss: 0.1535 - accuracy: 0.9460\n",
            "Epoch 86/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1538 - accuracy: 0.9429\n",
            "Epoch 87/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1524 - accuracy: 0.9424\n",
            "Epoch 88/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1507 - accuracy: 0.9461\n",
            "Epoch 89/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1527 - accuracy: 0.9449\n",
            "Epoch 90/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1442 - accuracy: 0.9469\n",
            "Epoch 91/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1451 - accuracy: 0.9455\n",
            "Epoch 92/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1394 - accuracy: 0.9494\n",
            "Epoch 93/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1456 - accuracy: 0.9457\n",
            "Epoch 94/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1453 - accuracy: 0.9456\n",
            "Epoch 95/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1450 - accuracy: 0.9486\n",
            "Epoch 96/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1519 - accuracy: 0.9467\n",
            "Epoch 97/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1389 - accuracy: 0.9493\n",
            "Epoch 98/100\n",
            "133/133 [==============================] - 5s 35ms/step - loss: 0.1420 - accuracy: 0.9487\n",
            "Epoch 99/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1375 - accuracy: 0.9488\n",
            "Epoch 100/100\n",
            "133/133 [==============================] - 5s 36ms/step - loss: 0.1287 - accuracy: 0.9513\n",
            "0.7658013701438904\n"
          ]
        }
      ],
      "source": [
        "# Compiling the model\n",
        "from tensorflow import keras\n",
        "\n",
        "time_results=np.zeros(6)\n",
        "\n",
        "for i in range(15,21):\n",
        "    \n",
        "    time_point=50*i\n",
        "    X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True,time_point)\n",
        "    x_train_valid_p = np.swapaxes(X_train_valid_prep, 2,1)\n",
        "    y_train_valid_p = to_categorical(y_train_valid_prep, 4)\n",
        "    X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True,time_point)\n",
        "    y_test_p = to_categorical(y_test_prep, 4)\n",
        "    x_test_p = np.swapaxes(X_test_prep, 2,1)\n",
        "    \n",
        "    print(y_test.shape)\n",
        "\n",
        "    print(x_train_valid_p.shape)\n",
        "    learning_rate = 1e-3\n",
        "    epochs = 100\n",
        "    decay_steps = 1000\n",
        "    cnn_optimizer = keras.optimizers.experimental.AdamW(learning_rate=learning_rate)\n",
        "\n",
        "    \n",
        "    basic_cnn_model = CNN_Transformer(intermediate_dim=6, num_heads=2, add_layer = True,time=int(time_point/2))\n",
        "    \n",
        "    basic_cnn_model.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=cnn_optimizer,\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "# Training and validating the model\n",
        "    basic_cnn_model_results = basic_cnn_model.fit(x_train_valid_p,\n",
        "                             y_train_valid_p,\n",
        "                             batch_size=64,\n",
        "                             epochs=epochs,\n",
        "                             verbose=True)\n",
        "    \n",
        "    cnn_score = basic_cnn_model.evaluate(x_test_p, y_test_p, verbose=0)[1]\n",
        "\n",
        "    print(cnn_score)\n",
        "\n",
        "    time_results[i-15]=cnn_score\n",
        "\n",
        "np.save(\"cnn_transformer_timestamp_750_1000_by_50_test_result.npy\",time_results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "9ad58eccf8dc77450abdd113d15799f9e5a14f39c013b7ee45fee60460cbd2d3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
